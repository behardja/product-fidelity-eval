import time

from google import genai
from google.genai import types
from google.genai.types import GenerateVideosConfig, Image, VideoGenerationReferenceImage
from google.adk.tools.tool_context import ToolContext

from ..config import (
    PROJECT_ID,
    LOCATION,
    VIDEO_GEN_MODEL,
    VIDEO_ASPECT_RATIO,
    VIDEO_GENERATE_AUDIO,
    VIDEO_DURATION_SECONDS,
    VIDEO_NUMBER_OF_VIDEOS,
    BUCKET_NAME,
)


VIDEO_RECONTEXTUALIZATION_PROMPT = (
    "Generate a short video showcasing the same product in a contextually "
    "appropriate setting. The video should NOT have a white background, and "
    "should be contextualized based on the product itself. "
    "For example, if the product is a bag, the video should show the bag in a "
    "natural ad or professional photo setting. If the product is a dress, the "
    "video should show the dress in a natural model photo setting. "
    "If there is a person in the original product image, create a variation "
    "of the person with the product without copying the exact same pose and "
    "environment as in the original image. "
    "Keep the product exactly as it is â€” do not alter its design, colors, "
    "logos, or any visual details."
)

POLL_INTERVAL = 15  # seconds between polling for video generation status


def generate_product_video(tool_context: ToolContext) -> dict:
    """Generate a recontextualized product video from the original product reference image(s).

    Takes the original product reference image(s) from state and generates a
    video showcasing the product in a contextually appropriate setting using
    the Veo 3.1 API.

    Returns:
        dict with 'video_uri' containing the GCS URI of the generated video.
    """
    client = genai.Client(
        vertexai=True,
        project=PROJECT_ID,
        location=LOCATION,
        http_options=types.HttpOptions(
            timeout=300 * 1000,
            retry_options=types.HttpRetryOptions(
                attempts=3,
                initial_delay=2.0,
                jitter=0.3,
                max_delay=30.0,
                http_status_codes=[408, 429, 500, 502, 503, 504],
            ),
        ),
    )

    # Build reference images from GCS URIs
    image_uris = tool_context.state.get("image_uris", "")
    uris = [u.strip() for u in image_uris.split(",") if u.strip()]

    reference_images = []
    for uri in uris:
        ext = uri.lower().rsplit(".", 1)[-1]
        mime = "image/jpeg" if ext in ("jpg", "jpeg") else f"image/{ext}"
        reference_images.append(
            VideoGenerationReferenceImage(
                image=Image(gcs_uri=uri, mime_type=mime),
                reference_type="asset",
            )
        )

    # Build the prompt
    attempt = tool_context.state.get("attempt", 1)
    if attempt > 1:
        refined = tool_context.state.get("current_description", "")
        failing = tool_context.state.get("failing_verdicts_text", "")
        prompt = (
            f"{VIDEO_RECONTEXTUALIZATION_PROMPT}\n\n"
            f"IMPORTANT: A previous attempt failed fidelity checks. "
            f"Pay extra attention to the following attributes that were NOT "
            f"faithfully reproduced:\n{failing}\n\n"
            f"Use this refined product description as guidance:\n{refined}"
        )
    else:
        prompt = VIDEO_RECONTEXTUALIZATION_PROMPT

    # Set output GCS path for the generated video
    sku_id = tool_context.state.get("sku_id", "unknown")
    output_gcs_uri = (
        f"gs://{BUCKET_NAME}/generated_videos/{sku_id}/attempt_{attempt}"
    )

    # Generate video using Veo
    operation = client.models.generate_videos(
        model=VIDEO_GEN_MODEL,
        prompt=prompt,
        config=GenerateVideosConfig(
            reference_images=reference_images,
            aspect_ratio=VIDEO_ASPECT_RATIO,
            generate_audio=VIDEO_GENERATE_AUDIO,
            duration_seconds=VIDEO_DURATION_SECONDS,
            number_of_videos=VIDEO_NUMBER_OF_VIDEOS,
            output_gcs_uri=output_gcs_uri,
        ),
    )

    # Poll until the operation completes
    while not operation.done:
        time.sleep(POLL_INTERVAL)
        operation = client.operations.get(operation)

    if operation.response and operation.result.generated_videos:
        video_uri = operation.result.generated_videos[0].video.uri
        tool_context.state["candidate_video_uri"] = video_uri
        return {"status": "success", "video_uri": video_uri}

    return {"status": "error", "message": "No video was generated by the model."}
