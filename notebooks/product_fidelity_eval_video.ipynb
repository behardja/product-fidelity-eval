{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2025 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Fidelity Evaluation with Gecko\n",
    "\n",
    "This notebook illustrates how to assess product image fidelity by using Gemini to create a detailed ground-truth description of a reference image, which then serves as the prompt for the rubric-based Gecko evaluation metric to score candidate images.\n",
    "\n",
    "Gemini is used to generate a detailed description of an original product image and then using that description as the \"prompt\" for Gecko.\n",
    "\n",
    "By generating a high-fidelity text description of your product, you effectively convert an **image-to-image consistency** task (checking if the generated product matches the original) into the **text-to-image alignment** task that Gecko is built to perform.\n",
    "\n",
    "The intent of this approach is to transform an image-consistency task into a text-alignment task, enabling \"rubric-based\" and \"interpretable\" nature to receive granular, diagnostic feedback on exactly which product details (such as color, shape, or texture) were preserved or lost.\n",
    "\n",
    "This process can be automated at scale using the Google Cloud GenAI Evaluation Suite. This notebook generates an evaluation report for HITL reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Evaluation Framework Overview\n",
    "\n",
    "Gecko is architected as a reference-free \"text-to-image\" evaluation metric that assesses alignment by verifying if specific keywords and attributes from a text prompt appear in a generated image.\n",
    "\n",
    "### The Rubric Generation Step \n",
    "\n",
    "This phase converts a text prompt into a comprehensive testing rubric. First, an LLM decomposes the prompt into key semantic elements (entities, attributes, and relationships) to ensure the evaluation covers the entire prompt rather than just parts of it. The system then generates specific Question-Answer (QA) pairs to verify these elements. Uniquely, Gecko employs a Natural Language Inference (NLI) model to filter these pairs, removing any hallucinated questions that are not factually grounded in the original text.\n",
    "\n",
    "\n",
    "### The Validator Step \n",
    "In this final stage, a multimodal model (such as Gemini) serves as the \"rubric validator,\" probing the generated media against the created QA pairs. Rather than simply marking answers as correct or incorrect, the validator calculates a normalized score based on the probability of the predicted answers. This approach captures the model's uncertainty, offering a more nuanced assessment of alignment than binary scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61RBz8LLbxCR"
   },
   "source": [
    "# Get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFy3H3aPgx12",
    "outputId": "80c62aad-2f79-4fbf-bbe0-20197502b23e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# @title ### Install Vertex AI SDK for Python and other required packages\n",
    "\n",
    "%pip install --upgrade --quiet \"google-cloud-aiplatform[evaluation]>=1.122.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NyKGtVQjgx13",
    "outputId": "6410feef-0617-41e0-c258-429f1f3cef44",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: google.colab.auth.authenticate_user() is not supported in Colab Enterprise.\n"
     ]
    }
   ],
   "source": [
    "# # @title ### Authenticate your notebook environment (Colab only)\n",
    "# # @markdown If you're running this notebook on Google Colab, run the cell below to authenticate your environment.\n",
    "\n",
    "# import sys\n",
    "\n",
    "# if \"google.colab\" in sys.modules:\n",
    "#     from google.colab import auth\n",
    "\n",
    "#     auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nqwi-5ufWp_B",
    "outputId": "681ff0ba-7895-45f6-f60c-3b07f0029002",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title ### Set Google Cloud project information\n",
    "# @markdown To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "# @markdown Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment).\n",
    "\n",
    "# @markdown ---\n",
    "\n",
    "PROJECT_ID = \"cpg-cdp\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
    "LOCATION= \"global\"  # @param {type: \"string\", placeholder: \"us-central1\", isTemplate: true}\n",
    "\n",
    "# from vertexai import Client, types\n",
    "from vertexai import types as vertex_types\n",
    "from vertexai import Client as VertexClient\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import pandas as pd\n",
    "\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkcZ0Ua_kWqU"
   },
   "source": [
    "# Generate Faithful Description based on Original Products\n",
    "\n",
    "Use Gemini to review the original product image and generate a description that accurately captures the details, difelity, and faithfulness of the product. This will description will act as the \"prompt\" which Gecko uses to evaluate text to image generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A_2LuJl2kWqU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-3-pro-preview\"\n",
    "\n",
    "system_instruction = \"\"\"\n",
    "You are an automated Visual Quality Assurance Specialist designed to support the text-to-image evaluation metric. Your task is to analyze an original product image and generate a comprehensive \"Ground Truth Description.\"\n",
    "\n",
    "Your output will be used as the reference prompt to evaluate if a generated image faithfully reproduces the original product. Therefore, precision, objectivity, and completeness are critical.\n",
    "\n",
    "**GUIDELINES:**\n",
    "\n",
    "1.  **Strict Objectivity:** Do not use subjective adjectives (e.g., \"beautiful,\" \"delicious,\" \"stunning,\" \"premium\"). Only describe what is visibly verifiable (e.g., \"matte finish,\" \"steaming,\" \"high-contrast,\" \"serif font\").\n",
    "\n",
    "2.  **Subject Isolation & Inference:**\n",
    "    *   **IGNORE HUMANS:** Treat any human elements (hands, faces, models, mannequins) as invisible background noise. Do not describe skin tone, poses, or body parts. Focus 100% of the description on the inanimate object being held, worn, or used.\n",
    "    *   **Product Identification:** If the product type is not explicitly labeled, use visual cues (form factor, ports, buttons, context) to make a high-confidence deduction of the product's identity (e.g., identifying a rectangular device with a lens as a \"compact digital camera\" rather than just a \"black box\").\n",
    "\n",
    "3.  **Attribute Exhaustiveness:** You must explicitly describe:\n",
    "    *   **Entities:** The core object(s) present (e.g., \"a ceramic coffee mug\").\n",
    "    *   **Colors:** Specific shades and color distribution (e.g., \"navy blue body with a white rim\").\n",
    "    *   **Textures/Materials:** Surface details (e.g., \"condensation droplets on glass,\" \"brushed aluminum,\" \"woven fabric pattern\").\n",
    "    *   **Text & Logos:** Transcribe visible text *exactly* as it appears, including capitalization and approximate location (e.g., \"the word 'COFFEE' printed in bold white letters at the center\").\n",
    "    *   **Spatial Relationships:** Where items are located relative to each other (e.g., \"the spoon rests to the right of the saucer\").\n",
    "\n",
    "4.  **Avoid Hallucination:** Do not invent details that are obscured or implied. If a label is unreadable, do not guess the text. Only describe what is clearly visible in pixels.\n",
    "\n",
    "5.  **Format:** Output a single, dense, coherent paragraph. Semantic decomposition works best with complete sentences that establish relationships between objects and their attributes.\n",
    "\"\"\"\n",
    "\n",
    "text_prompt = \"\"\"\n",
    "I am providing reference images of the SAME product. Your goal is to synthesize a single, definitive \"Ground Truth\" description that unifies all visual data from these inputs.\n",
    "\n",
    "**CRITICAL INSTRUCTIONS:**\n",
    "*   **Human Exclusion:** If the image features a person holding, wearing, or interacting with the product, completely ignore the person in your description. Do not mention hands, fingers, or models. Act as if the product is floating in the air or placed on a neutral surface.\n",
    "*  **Background Exclusion:** Do not describe the surrounding environment, scenery, or surface on which the product rests. Whether the background is a solid color, a cluttered room, or an outdoor landscape, treat it as invisible. Your description must remain strictly within the physical boundaries of the product itself.\n",
    "*   **Holistic Synthesis:** Merge details from all angles (front, back, side) into one coherent object profile. If a feature (e.g., a port, label, or texture) is visible in only one image, treat it as a permanent feature of the product.\n",
    "*   **Intrinsic Properties:** Filter out lighting artifacts (glare, shadows, flash) to describe the object's actual local colors and material finishes.\n",
    "*   **High-Fidelity Nuances:** You must capture the following specific dimensions:\n",
    "    *   **Deductive Object Identity:** Explicitly name the product based on its visual features. If the exact model is unknown, provide the most accurate category description possible (e.g., \"wireless over-ear noise-canceling headphones\").\n",
    "    *   **Materiality:** Specific surface qualities (e.g., \"brushed aluminum,\" \"knitted wool,\" \"matte rubberized grip,\" \"transparent glass\").\n",
    "    *   **Surface Graphics:** Explicitly describe any patterns, gradients, prints, or woven designs.\n",
    "    *   **Typography & Data:** Transcribe all visible text, logos, and numbers *verbatim*, noting their color and placement.\n",
    "\n",
    "**OUTPUT FORMAT:**\n",
    "Produce a single, dense, highly descriptive paragraph. 750 words max.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RsLHYP7ikWqV",
    "outputId": "327a34b7-57a3-4438-e816-a7587e798e34",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/beusebio/venvs/default/lib/python3.13/site-packages/google/auth/_default.py:114: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This visible object is an inflatable, full-body costume designed to resemble a standing, anthropomorphic unicorn. The costume is constructed from a lightweight, white synthetic material, likely nylon or polyester, which exhibits a puffy, billowy volume with soft wrinkles characteristic of fan-inflated garments. The large, oversized head features a conical yellow horn with spiral segmentation at the crown and two ears with white exteriors and purple triangular interiors. A prominent, bulbous pink snout section defines the face, detailed with a simple black curved line depicting a mouth and a vertical center seam. On the cheek, there is a small, dark graphic element resembling a star. Positioned directly beneath the unicorn's chin, at the neck level, is a clear, rectangular plastic viewing window. The torso is dominated by a large, light teal-blue oval panel covering the belly area, bisected by a vertical seam. The upper limbs consist of inflated white sleeves that terminate in distinct purple gloves serving as front hooves. The lower body features thick, stubby white legs ending in purple, hoof-shaped foot coverings. A glimpse of a yellow tail is visible between the legs at the rear.\n"
     ]
    }
   ],
   "source": [
    "# @title Input Images (GCS)\n",
    "# Replace these with your actual GCS paths\n",
    "gcs_image_uris = [\n",
    "    \"gs://sandbox-401718-product-fidelity-eval/SKU007-unicorn.jpg\",\n",
    "    # \"gs://andbox-401718-product-fidelity-evals/side_view.png\",\n",
    "]\n",
    "\n",
    "content_parts = []\n",
    "\n",
    "# Add image parts using URIs\n",
    "for uri in gcs_image_uris:\n",
    "    content_parts.append(\n",
    "        types.Part.from_uri(file_uri=uri, mime_type=\"image/png\")\n",
    "    )\n",
    "\n",
    "content_parts.append(text_prompt)\n",
    "\n",
    "# Generate the description\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=content_parts,\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_instruction,\n",
    "        temperature=1,\n",
    "    ),\n",
    ")\n",
    "\n",
    "generated_ground_truth_prompt = response.text\n",
    "print(generated_ground_truth_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gv7YyT-l657I"
   },
   "source": [
    "# Prepare the Evaluation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_pfeWdR65rv"
   },
   "source": [
    "In the following dataset, two prompts are used for each generated image. The first is the prompt that corresponds to the generated content. The second is a counterexample that is similar but does not exactly match the generated content. This is done to demonstrate the difference in the Gecko evaluation for high quality and low quality responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SJ7TrMJ2kWqW",
    "outputId": "8647719d-bec8-4b57-eba5-1f35dd447400",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 1 items.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This visible object is an inflatable, full-bod...</td>\n",
       "      <td>{'parts': [{'file_data': {'mime_type': 'video/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  This visible object is an inflatable, full-bod...   \n",
       "\n",
       "                                            response  \n",
       "0  {'parts': [{'file_data': {'mime_type': 'video/...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Create Evaluation Dataset (GCS)\n",
    "\n",
    "# Define your prompts (using the description generated in the previous step)\n",
    "# We repeat the prompt for however many images we are evaluating\n",
    "ground_truth_prompt = generated_ground_truth_prompt \n",
    "\n",
    "# Define the GCS paths for the images you want to score\n",
    "# (e.g., one high quality, one low quality)\n",
    "eval_video_uris = [\n",
    "    \"gs://sandbox-401718-product-fidelity-eval/generated/01-unicorn-veo.mp4\", \n",
    "]\n",
    "\n",
    "# Construct Responses list using file_uri structure\n",
    "responses = []\n",
    "\n",
    "for uri in eval_video_uris:\n",
    "    responses.append({\n",
    "        \"parts\": [\n",
    "            {\n",
    "                \"file_data\": {\n",
    "                    \"mime_type\": \"video/mp4\", \n",
    "                    \"file_uri\": uri\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"role\": \"model\",\n",
    "    })\n",
    "\n",
    "# Create Prompts list matching the length of Responses\n",
    "prompts = [ground_truth_prompt] * len(responses)\n",
    "\n",
    "# Create the DataFrame\n",
    "eval_dataset = pd.DataFrame(\n",
    "    {\n",
    "        \"prompt\": prompts,\n",
    "        \"response\": responses,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Dataset created with {len(eval_dataset)} items.\")\n",
    "eval_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qm6mHoPc-DS0"
   },
   "source": [
    "# Run evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_lyccWc5kWqW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from vertexai import Client, types\n",
    "\n",
    "vertex_client = VertexClient(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AfgCsW1MZ8dj",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/beusebio/venvs/default/lib/python3.13/site-packages/google/auth/_default.py:114: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/google/home/beusebio/venvs/default/lib/python3.13/site-packages/google/auth/_default.py:114: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/google/home/beusebio/venvs/default/lib/python3.13/site-packages/google/auth/_default.py:114: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# @title ### Generate rubrics\n",
    "# @markdown First we generate rubrics for the user prompts.\n",
    "\n",
    "data_with_rubrics = vertex_client.evals.generate_rubrics(\n",
    "    src=eval_dataset,\n",
    "    rubric_group_name=\"gecko_video_rubrics\",\n",
    "    predefined_spec_name=vertex_types.RubricMetric.GECKO_TEXT2VIDEO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "f-rIsIyblR8Y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_with_rubrics.show() # crashes because of bytes input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "t99YmQDCnU73",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the first row's 'rubric_groups' cell\n",
    "first_row_data = data_with_rubrics.eval_dataset_df['rubric_groups'].iloc[0]\n",
    "\n",
    "# Access the specific rubric list using the key seen in your screenshot\n",
    "rubrics_list = first_row_data['gecko_video_rubrics']\n",
    "\n",
    "# Prints\n",
    "# Iterate and print the details\n",
    "# print(f\"Found {len(rubrics_list)} rubric questions:\\n\")\n",
    "\n",
    "# for i, rubric in enumerate(rubrics_list):\n",
    "#     print(f\"--- Question {i+1} ---\")\n",
    "#     print(rubric)\n",
    "#     # If the output is still cluttered, try printing specific attributes:\n",
    "#     # print(f\"Question: {rubric.description}\")\n",
    "#     # print(f\"Score: {rubric.score}\")\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMuDxiwy-MTt",
    "outputId": "9b859cd1-c8f0-4b5a-a2ad-353fc0034f7f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Metrics for Evaluation Dataset: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:27<00:00, 27.81s/it]\n"
     ]
    }
   ],
   "source": [
    "# @title ### Evaluate with rubrics\n",
    "# @markdown Then we use the generated rubrics to evaluate the quality of the responses.\n",
    "\n",
    "eval_result = vertex_client.evals.evaluate(\n",
    "    dataset=data_with_rubrics,\n",
    "    metrics=[vertex_types.RubricMetric.GECKO_TEXT2VIDEO],\n",
    ")\n",
    "\n",
    "# eval_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0slWdh5vhN2"
   },
   "source": [
    "### Generate Product Report for HITL Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-3YRQ2-tpS1O",
    "outputId": "e896cd73-5c12-4782-89ad-0da8166f3450",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report generated successfully: gecko_report.html\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import html\n",
    "import os\n",
    "from google.cloud import storage\n",
    "\n",
    "def _load_media_as_base64(path: str) -> tuple[str, str, str]:\n",
    "    \"\"\"\n",
    "    Load media (image or video) from a local path or GCS URI and return (base64_data, mime_type, media_category).\n",
    "    Returns (None, None, None) if the media cannot be loaded.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Determine mime type from extension\n",
    "        ext = path.lower().split('.')[-1]\n",
    "        mime_map = {\n",
    "            'png': ('image/png', 'image'),\n",
    "            'jpg': ('image/jpeg', 'image'),\n",
    "            'jpeg': ('image/jpeg', 'image'),\n",
    "            'gif': ('image/gif', 'image'),\n",
    "            'webp': ('image/webp', 'image'),\n",
    "            'mp4': ('video/mp4', 'video'),\n",
    "            'mov': ('video/quicktime', 'video'),\n",
    "            'webm': ('video/webm', 'video')\n",
    "        }\n",
    "        mime_type, media_category = mime_map.get(ext, ('image/png', 'image'))\n",
    "\n",
    "        if path.startswith('gs://'):\n",
    "            # Parse GCS path\n",
    "            path_without_prefix = path[5:]  # Remove 'gs://'\n",
    "            bucket_name = path_without_prefix.split('/')[0]\n",
    "            blob_path = '/'.join(path_without_prefix.split('/')[1:])\n",
    "\n",
    "            # Download from GCS\n",
    "            client = storage.Client()\n",
    "            bucket = client.bucket(bucket_name)\n",
    "            blob = bucket.blob(blob_path)\n",
    "            media_bytes = blob.download_as_bytes()\n",
    "        else:\n",
    "            # Local file\n",
    "            with open(path, 'rb') as f:\n",
    "                media_bytes = f.read()\n",
    "\n",
    "        b64_data = base64.b64encode(media_bytes).decode('utf-8')\n",
    "        return b64_data, mime_type, media_category\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load media {path}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def create_gecko_html_report(eval_result, source_uris=None, filename=\"gecko_report.html\"):\n",
    "  \"\"\"\n",
    "  Generates an HTML report with collapsible candidate media sections.\n",
    "  \"\"\"\n",
    "\n",
    "  # 1. Access Data safely\n",
    "  try:\n",
    "    df = eval_result.evaluation_dataset[0].eval_dataset_df\n",
    "  except (AttributeError, IndexError):\n",
    "    print(\"Error: Could not find evaluation dataset in result object.\")\n",
    "    return\n",
    "\n",
    "  results = eval_result.eval_case_results\n",
    "\n",
    "  # Extract the Global Prompt\n",
    "  global_prompt_text = str(df.iloc[0]['prompt'])\n",
    "\n",
    "  # Handle Summary Metrics\n",
    "  if eval_result.summary_metrics:\n",
    "    summary = eval_result.summary_metrics[0]\n",
    "    s_val = summary.mean_score if summary.mean_score is not None else 0.0\n",
    "    mean_score = f\"{s_val:.2f}\"\n",
    "  else:\n",
    "    mean_score = \"N/A\"\n",
    "\n",
    "  # --- BUILD SOURCE MEDIA HTML (with actual media) ---\n",
    "  source_media_html = \"\"\n",
    "  if source_uris:\n",
    "    for uri in source_uris:\n",
    "      name = uri.split('/')[-1]\n",
    "      b64_data, mime_type, media_category = _load_media_as_base64(uri)\n",
    "\n",
    "      if b64_data:\n",
    "        if media_category == 'video':\n",
    "            media_tag = f'<video src=\"data:{mime_type};base64,{b64_data}\" controls style=\"max-height: 160px; max-width: 200px; border-radius: 4px; border: 1px solid #ccc;\"></video>'\n",
    "        else:\n",
    "            media_tag = f'<img src=\"data:{mime_type};base64,{b64_data}\" alt=\"{html.escape(name)}\" style=\"max-height: 160px; max-width: 200px; border-radius: 4px; border: 1px solid #ccc;\">'\n",
    "      else:\n",
    "        media_tag = f'''<div style=\"height: 160px; width: 160px; background: #eee; display: flex; align-items: center; justify-content: center; border: 1px solid #ccc; border-radius: 4px;\">\n",
    "           <span style=\"font-size: 0.8em; color: #555;\">Failed to load:<br>{html.escape(name)}</span>\n",
    "        </div>'''\n",
    "\n",
    "      source_media_html += f\"\"\"\n",
    "      <div class=\"orig-item\">\n",
    "        {media_tag}\n",
    "        <div class=\"orig-label\">{html.escape(name)}</div>\n",
    "      </div>\n",
    "      \"\"\"\n",
    "\n",
    "  # 2. Start HTML String with updated CSS for collapsible sections\n",
    "  html_content = f\"\"\"\n",
    "  <!DOCTYPE html>\n",
    "  <html lang=\"en\">\n",
    "  <head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Gecko Evaluation Report</title>\n",
    "    <style>\n",
    "      body {{ font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; margin: 0; background: #f4f4f4; color: #333; }}\n",
    "      .main-container {{ max-width: 1200px; margin: 30px auto; background: white; padding: 30px; border-radius: 8px; box-shadow: 0 2px 15px rgba(0,0,0,0.08); }}\n",
    "      h1 {{ color: #1a73e8; margin-top: 0; border-bottom: 2px solid #eee; padding-bottom: 10px; }}\n",
    "      .ground-truth-section {{ display: flex; gap: 20px; margin-bottom: 30px; background: #fff; border: 1px solid #e0e0e0; border-radius: 8px; padding: 20px; }}\n",
    "      .gt-images {{ flex: 1; display: flex; gap: 15px; flex-wrap: wrap; }}\n",
    "      .orig-item {{ text-align: center; }}\n",
    "      .gt-prompt-box {{ flex: 1.2; background: #f8f9fa; border: 1px solid #eee; border-radius: 4px; padding: 15px; display: flex; flex-direction: column; }}\n",
    "      .gt-prompt-label {{ font-weight: bold; color: #1a73e8; margin-bottom: 8px; font-size: 0.9em; text-transform: uppercase; }}\n",
    "      .gt-prompt-text {{ font-size: 0.9em; line-height: 1.5; color: #444; overflow-y: auto; max-height: 200px; white-space: pre-wrap; }}\n",
    "      .summary-bar {{ background: #e8f0fe; padding: 12px 20px; border-radius: 5px; margin-bottom: 25px; border-left: 5px solid #1a73e8; display: flex; gap: 30px; align-items: center; }}\n",
    "      .summary-val {{ font-weight: bold; color: #1a73e8; }}\n",
    "\n",
    "      /* Collapsible candidate styles */\n",
    "      .candidate-list {{ display: flex; flex-direction: column; gap: 12px; }}\n",
    "      .candidate-item {{ border: 1px solid #e0e0e0; border-radius: 8px; overflow: hidden; }}\n",
    "      .candidate-item[open] {{ box-shadow: 0 2px 8px rgba(0,0,0,0.1); }}\n",
    "      .candidate-item summary {{\n",
    "        padding: 15px 20px;\n",
    "        background: #fafafa;\n",
    "        cursor: pointer;\n",
    "        display: flex;\n",
    "        align-items: center;\n",
    "        gap: 15px;\n",
    "        list-style: none;\n",
    "        border-bottom: 1px solid transparent;\n",
    "      }}\n",
    "      .candidate-item[open] summary {{\n",
    "        border-bottom-color: #e0e0e0;\n",
    "        background: #f5f5f5;\n",
    "      }}\n",
    "      .candidate-item summary::-webkit-details-marker {{ display: none; }}\n",
    "      .candidate-item summary::before {{\n",
    "        content: \"\\\\25B6\";\n",
    "        font-size: 0.7em;\n",
    "        color: #666;\n",
    "        transition: transform 0.2s;\n",
    "      }}\n",
    "      .candidate-item[open] summary::before {{\n",
    "        transform: rotate(90deg);\n",
    "      }}\n",
    "      .summary-info {{ flex: 1; display: flex; align-items: center; gap: 15px; }}\n",
    "      .summary-name {{ font-weight: 500; color: #333; }}\n",
    "      .summary-stats {{ color: #666; font-size: 0.85em; }}\n",
    "\n",
    "      .candidate-content {{ padding: 20px; display: flex; gap: 20px; background: #fff; }}\n",
    "      .candidate-media {{ flex: 0 0 450px; }}\n",
    "      .candidate-media img, .candidate-media video {{ max-width: 100%; height: auto; border-radius: 4px; border: 1px solid #eee; }}\n",
    "      .candidate-media .gcs-placeholder {{\n",
    "        height: 200px;\n",
    "        background: #f0f0f0;\n",
    "        display: flex;\n",
    "        align-items: center;\n",
    "        justify-content: center;\n",
    "        border-radius: 4px;\n",
    "        text-align: center;\n",
    "        padding: 10px;\n",
    "      }}\n",
    "      .candidate-verdicts {{ flex: 1; }}\n",
    "\n",
    "      .score-badge {{ display: inline-block; padding: 5px 12px; border-radius: 15px; font-weight: bold; font-size: 0.9em; }}\n",
    "      .score-high {{ background: #e6f4ea; color: #188038; }}\n",
    "      .score-medium {{ background: #fef7e0; color: #b06000; }}\n",
    "      .score-low {{ background: #fce8e6; color: #d93025; }}\n",
    "\n",
    "      .rubric-list {{ list-style-type: none; padding: 0; margin: 0; }}\n",
    "      .rubric-item {{ margin-bottom: 6px; padding: 10px 12px; background: #fafafa; border: 1px solid #eee; border-left-width: 4px; border-radius: 4px; font-size: 0.9em; }}\n",
    "      .rubric-pass {{ border-left-color: #188038; background: #f6fef7; }}\n",
    "      .rubric-fail {{ border-left-color: #d93025; background: #fef7f6; }}\n",
    "      .rubric-icon {{ margin-right: 8px; }}\n",
    "\n",
    "      .verdict-summary {{ margin-bottom: 15px; padding: 10px 15px; background: #f8f9fa; border-radius: 4px; font-size: 0.85em; color: #555; }}\n",
    "\n",
    "      /* Expand/Collapse All buttons */\n",
    "      .controls {{ margin-bottom: 15px; display: flex; gap: 10px; }}\n",
    "      .controls button {{\n",
    "        padding: 8px 16px;\n",
    "        border: 1px solid #1a73e8;\n",
    "        background: white;\n",
    "        color: #1a73e8;\n",
    "        border-radius: 4px;\n",
    "        cursor: pointer;\n",
    "        font-size: 0.85em;\n",
    "      }}\n",
    "      .controls button:hover {{ background: #e8f0fe; }}\n",
    "    </style>\n",
    "  </head>\n",
    "  <body>\n",
    "  <div class=\"main-container\">\n",
    "    <h1>Gecko Evaluation Report</h1>\n",
    "    <div class=\"ground-truth-section\">\n",
    "      <div class=\"gt-images\">{source_media_html}</div>\n",
    "      <div class=\"gt-prompt-box\">\n",
    "        <div class=\"gt-prompt-label\">Ground Truth Prompt</div>\n",
    "        <div class=\"gt-prompt-text\">{html.escape(global_prompt_text)}</div>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div class=\"summary-bar\">\n",
    "      <div class=\"summary-item\">Average Score: <span class=\"summary-val\">{mean_score} / 1.0</span></div>\n",
    "      <div class=\"summary-item\">Total Candidates: <span class=\"summary-val\">{len(results)}</span></div>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"controls\">\n",
    "      <button onclick=\"document.querySelectorAll('.candidate-item').forEach(d => d.open = true)\">Expand All</button>\n",
    "      <button onclick=\"document.querySelectorAll('.candidate-item').forEach(d => d.open = false)\">Collapse All</button>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"candidate-list\">\n",
    "  \"\"\"\n",
    "\n",
    "  # 3. Iterate through results\n",
    "  for case in results:\n",
    "    index = case.eval_case_index\n",
    "    metric_data = case.response_candidate_results[0].metric_results\n",
    "    metric_key = list(metric_data.keys())[0]\n",
    "    data = metric_data[metric_key]\n",
    "    score = data.score if data.score is not None else 0.0\n",
    "    verdicts = data.rubric_verdicts\n",
    "\n",
    "    # Get Original Data\n",
    "    row = df.iloc[index]\n",
    "\n",
    "    # Determine score class\n",
    "    if score >= 0.7:\n",
    "      score_class = \"score-high\"\n",
    "    elif score >= 0.4:\n",
    "      score_class = \"score-medium\"\n",
    "    else:\n",
    "      score_class = \"score-low\"\n",
    "\n",
    "    # Extract media name and build media HTML\n",
    "    media_name = f\"Candidate {index + 1}\"\n",
    "    try:\n",
    "      parts = row['response'].get('parts', [])\n",
    "      if parts and 'file_data' in parts[0]:\n",
    "          file_uri = parts[0]['file_data']['file_uri']\n",
    "          media_name = file_uri.split('/')[-1]\n",
    "\n",
    "          # Load actual media from GCS\n",
    "          b64_data, mime_type, media_category = _load_media_as_base64(file_uri)\n",
    "          if b64_data:\n",
    "              if media_category == 'video':\n",
    "                  media_html = f'<video src=\"data:{mime_type};base64,{b64_data}\" controls></video>'\n",
    "              else:\n",
    "                  media_html = f'<img src=\"data:{mime_type};base64,{b64_data}\" alt=\"{html.escape(media_name)}\">'\n",
    "          else:\n",
    "              gcs_link = f\"https://console.cloud.google.com/storage/browser/_details/{file_uri.replace('gs://', '')}\"\n",
    "              media_html = f\"\"\"<div class=\"gcs-placeholder\">\n",
    "                <div>\n",
    "                  <div style=\"font-size: 2em; margin-bottom: 10px;\">\u26a0\ufe0f</div>\n",
    "                  <div style=\"font-size: 0.85em; color: #d93025;\">Failed to load media</div>\n",
    "                  <a href=\"{gcs_link}\" target=\"_blank\" style=\"font-size: 0.8em;\">{html.escape(media_name)}</a>\n",
    "                </div>\n",
    "              </div>\"\"\"\n",
    "      elif parts and 'inline_data' in parts[0]:\n",
    "          media_bytes = parts[0]['inline_data']['data']\n",
    "          b64_media = base64.b64encode(media_bytes).decode('utf-8')\n",
    "          mime_type = parts[0]['inline_data'].get('mime_type', 'image/png')\n",
    "          if mime_type.startswith('video/'):\n",
    "              media_html = f'<video src=\"data:{mime_type};base64,{b64_media}\" controls></video>'\n",
    "          else:\n",
    "              media_html = f'<img src=\"data:{mime_type};base64,{b64_media}\" alt=\"Generated Media\">'\n",
    "      else:\n",
    "         media_html = \"<div class='gcs-placeholder'><div style='color:orange;'>No media data</div></div>\"\n",
    "    except Exception as e:\n",
    "      media_html = f\"<div class='gcs-placeholder'><div style='color:red;'>Media Error: {e}</div></div>\"\n",
    "\n",
    "    # Count pass/fail verdicts\n",
    "    pass_count = 0\n",
    "    fail_count = 0\n",
    "    verdicts_html = \"<ul class='rubric-list'>\"\n",
    "    if verdicts:\n",
    "      for v in verdicts:\n",
    "        raw_verdict = getattr(v, 'verdict', False)\n",
    "        is_pass = str(raw_verdict).lower() == 'true'\n",
    "        if is_pass:\n",
    "          pass_count += 1\n",
    "          css_class = \"rubric-pass\"\n",
    "          icon = \"\u2713\"\n",
    "        else:\n",
    "          fail_count += 1\n",
    "          css_class = \"rubric-fail\"\n",
    "          icon = \"\u2717\"\n",
    "        try:\n",
    "          text = v.evaluated_rubric.content.property.description\n",
    "        except AttributeError:\n",
    "          text = str(v)\n",
    "        verdicts_html += f\"<li class='rubric-item {css_class}'><span class='rubric-icon'>{icon}</span>{html.escape(str(text))}</li>\"\n",
    "    else:\n",
    "       verdicts_html += \"<li class='rubric-item'>No details available</li>\"\n",
    "    verdicts_html += \"</ul>\"\n",
    "\n",
    "    total_verdicts = pass_count + fail_count\n",
    "    verdict_summary = f\"{pass_count} passed, {fail_count} failed\" if total_verdicts > 0 else \"No verdicts\"\n",
    "\n",
    "    # Build collapsible section (open by default for low scores)\n",
    "    open_attr = \"open\" if score < 0.7 else \"\"\n",
    "\n",
    "    html_content += f\"\"\"\n",
    "      <details class=\"candidate-item\" {open_attr}>\n",
    "        <summary>\n",
    "          <div class=\"summary-info\">\n",
    "            <span class=\"summary-name\">{html.escape(media_name)}</span>\n",
    "            <span class=\"score-badge {score_class}\">{score:.2f}</span>\n",
    "            <span class=\"summary-stats\">{verdict_summary}</span>\n",
    "          </div>\n",
    "        </summary>\n",
    "        <div class=\"candidate-content\">\n",
    "          <div class=\"candidate-media\">\n",
    "            {media_html}\n",
    "          </div>\n",
    "          <div class=\"candidate-verdicts\">\n",
    "            <div class=\"verdict-summary\">\n",
    "              <strong>Rubric Results:</strong> {pass_count}/{total_verdicts} criteria passed\n",
    "            </div>\n",
    "            {verdicts_html}\n",
    "          </div>\n",
    "        </div>\n",
    "      </details>\n",
    "    \"\"\"\n",
    "\n",
    "  html_content += \"\"\"\n",
    "    </div>\n",
    "  </div>\n",
    "  </body>\n",
    "  </html>\n",
    "  \"\"\"\n",
    "\n",
    "  with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "  print(f\"Report generated successfully: {filename}\")\n",
    "\n",
    "create_gecko_html_report(eval_result, source_uris=gcs_image_uris)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "product_fidelity_eval_with_gecko.ipynb",
   "provenance": []
  },
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m117"
  },
  "kernelspec": {
   "display_name": "Default (venv)",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}